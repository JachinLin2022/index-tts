{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['VLLM_USE_V1'] = '0'\n",
    "from indextts.infer_v2_vllm import IndexTTS2\n",
    "# from indextts.infer_v2 import IndexTTS2\n",
    "import asyncio\n",
    "index_tts = IndexTTS2(cfg_path=\"checkpoints/config.yaml\", model_dir=\"checkpoints\", use_cuda_kernel=False, gpu_memory_utilization=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import types\n",
    "from pydub import AudioSegment\n",
    "from indextts import infer_v2_vllm\n",
    "from indextts.s2mel.modules import diffusion_transformer\n",
    "from indextts.s2mel.modules import flow_matching\n",
    "from indextts.utils import front\n",
    "importlib.reload(infer_v2_vllm)\n",
    "importlib.reload(diffusion_transformer)\n",
    "importlib.reload(flow_matching)\n",
    "importlib.reload(front)\n",
    "from indextts.infer_v2_vllm import IndexTTS2\n",
    "from indextts.s2mel.modules.flow_matching import CFM\n",
    "from indextts.s2mel.modules.diffusion_transformer import DiT\n",
    "import time\n",
    "\n",
    "index_tts.infer_stream = types.MethodType(IndexTTS2.infer_stream, index_tts)\n",
    "index_tts.infer_stream_optimized = types.MethodType(IndexTTS2.infer_stream_optimized, index_tts)\n",
    "index_tts.infer_parallel = types.MethodType(IndexTTS2.infer_parallel, index_tts)\n",
    "index_tts.tokenizer.split_segments = types.MethodType(front.TextTokenizer.split_segments, index_tts.tokenizer)\n",
    "# index_tts.front = types.MethodType(front.Front.load, index_tts.front)\n",
    "index_tts.s2mel.models['cfm'].solve_euler = types.MethodType(CFM.solve_euler, index_tts.s2mel.models['cfm'])\n",
    "index_tts.s2mel.models['cfm'].estimator.forward = types.MethodType(DiT.forward, index_tts.s2mel.models['cfm'].estimator)\n",
    "\n",
    "count = 0\n",
    "concat_segment = None\n",
    "from io import BytesIO\n",
    "start_time = time.time()\n",
    "async for chunk in index_tts.infer_stream_optimized(spk_audio_prompt='/root/RichooAgent/data/Female 1.mp3', text=\"\"\"Encouraging Consistent Chess Practice. Tom could benefit from more consistent practice to really solidify his understanding and skills in chess. This is a common area for growth, and with some focused effort, we'll see great progress. To help Tom get more accustomed to chess, we recommend establishing a fun, regular practice routine at home. Tom could try playing one or two quick games daily, either with family or on a platform like ChessKid. Solving a few chess puzzles each week through an app or workbook is also an excellent way to sharpen his mind. Aiming for around 2-4 hours of practice a week will build a strong foundation and keep the game enjoyable and engaging for him.\"\"\", output_path=\"test_parallel2.wav\", verbose=False, max_text_tokens_per_segment=120, interval_silence=0, first_handle_num=1, crossfade_ms=100):\n",
    "    # print(len(chunk))\n",
    "    # pass\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to receive chunk: {end_time - start_time:.2f} seconds, size: {len(chunk)}\")\n",
    "    start_time = end_time\n",
    "\n",
    "    # with open(f\"test_stream_{count}.wav\", \"wb\") as f:\n",
    "    #     f.write(chunk)\n",
    "    if concat_segment is None:\n",
    "        # concat_segment = AudioSegment.from_file(BytesIO(chunk), format=\"mp3\")\n",
    "        concat_segment = AudioSegment.from_raw(BytesIO(chunk), sample_width=2, frame_rate=22050, channels=1)\n",
    "    else:\n",
    "        # concat_segment = concat_segment.append(AudioSegment.from_file(BytesIO(chunk), format=\"mp3\"), crossfade=0)\n",
    "        concat_segment = concat_segment.append(AudioSegment.from_raw(BytesIO(chunk), sample_width=2, frame_rate=22050, channels=1), crossfade=0)\n",
    "    \n",
    "concat_segment.export(\"test_stream.mp3\", format=\"mp3\")\n",
    "# await index_tts.infer_parallel(spk_audio_prompt='data/test_real.wav', text=\"\"\"Tom could benefit from more consistent practice to really solidify his understanding and skills in chess. This is a common area for growth, and with some focused effort, we'll see great progress. To help Tom get more accustomed to chess, we recommend establishing a fun, regular practice routine at home. Tom could try playing one or two quick games daily, either with family or on a platform like ChessKid. Solving a few chess puzzles each week through an app or workbook is also an excellent way to sharpen his mind. Aiming for around 2-4 hours of practice a week will build a strong foundation and keep the game enjoyable and engaging for him.\"\"\", output_path=\"test_parallel2.wav\", verbose=False, max_text_tokens_per_segment=120, interval_silence=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# 加载两个音频文件\n",
    "audio1 = AudioSegment.from_mp3(\"test_stream_1.wav\")\n",
    "audio2 = AudioSegment.from_mp3(\"test_stream_2.wav\")\n",
    "\n",
    "merged_chunk = audio1.append(audio2, crossfade=0)\n",
    "merged_chunk.export(\"merged_chunk.mp3\", format=\"mp3\")\n",
    "# def stream_with_crossfade(audio1, audio2, crossfade_ms=250):\n",
    "#     # Step 1: 播放 audio1 主体部分（除去最后 crossfade_ms）\n",
    "#     main_part = audio1[:-crossfade_ms]\n",
    "#     yield main_part.raw_data  # 或导出为临时文件/分块传输\n",
    "\n",
    "#     # Step 2: 交叉淡出淡入部分\n",
    "#     fade_out = audio1[-crossfade_ms:].fade_out(crossfade_ms)\n",
    "#     fade_in = audio2[:crossfade_ms].fade_in(crossfade_ms)\n",
    "#     crossfaded = fade_out.overlay(fade_in)  # 混合\n",
    "#     yield crossfaded.raw_data\n",
    "\n",
    "#     # Step 3: 播放 audio2 剩余部分\n",
    "#     remaining = audio2[crossfade_ms:]\n",
    "#     yield remaining.raw_data\n",
    "# crossfade_ms = 250\n",
    "# a1 = audio1[:-crossfade_ms]\n",
    "# a2 = audio2[crossfade_ms:]\n",
    "# fade_out = audio1[-crossfade_ms:].fade_out(crossfade_ms)\n",
    "# fade_in = audio2[:crossfade_ms].fade_in(crossfade_ms)\n",
    "# crossfaded = fade_out.overlay(fade_in)\n",
    "\n",
    "# merged_chunk = a1.append(crossfaded, crossfade=0)\n",
    "# merged_chunk = merged_chunk.append(a2, crossfade=0)\n",
    "# merged_chunk.export(\"merged_chunk.mp3\", format=\"mp3\")\n",
    "# with open(\"merged_chunk.mp3\", \"wb\") as f:\n",
    "    # f.write(a1 + crossfaded + a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import time\n",
    "payload = {\n",
    "    \"prompt_audio_url\": \"https://beezstorageblob.blob.core.windows.net/emailblob/cloned_voice_0e3a2d2d-7a24-41d2-b1f5-c7af7f3ab284.wav\",\n",
    "    \"text\": \"\"\"```title\\n## Encouraging Consistent Chess Practice\\n```\\n```report\\nTom could benefit from more consistent practice to really solidify his understanding and skills in chess. This is a common area for growth, and with some focused effort, we'll see great progress.\\n\\nTo help Tom get more accustomed to chess, we recommend establishing a fun, regular practice routine at home. Tom could try playing one or two quick games daily, either with family or on a platform like ChessKid. Solving a few chess puzzles each week through an app or workbook is also an excellent way to sharpen his mind. Aiming for around 2-4 hours of practice a week will build a strong foundation and keep the game enjoyable and engaging for him.\\n```\"\"\",\n",
    "}\n",
    "\n",
    "concat_segment = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    with httpx.stream(\"POST\", \"http://127.0.0.1:62343/generate-speech-stream/\", json=payload, follow_redirects=True) as r:\n",
    "        # r.raise_for_status() # Ensure the request was successful\n",
    "        start_time = time.time()\n",
    "        for chunk in r.iter_bytes():\n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken to receive chunk: {end_time - start_time:.2f} seconds, size: {len(chunk)}\")\n",
    "            start_time = end_time\n",
    "            if concat_segment is None:\n",
    "                concat_segment = AudioSegment.from_file(BytesIO(chunk))\n",
    "            else:\n",
    "                concat_segment = concat_segment.append(AudioSegment.from_file(BytesIO(chunk)), crossfade=0)\n",
    "            break\n",
    "    concat_segment.export(\"test_stream.mp3\", format=\"mp3\")\n",
    "except httpx.HTTPError as e:\n",
    "    print(f\"An HTTP error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcribe base64\n",
    "import base64\n",
    "import requests\n",
    "# with open(\"test_stream.mp3\", \"rb\") as f:\n",
    "with open(\"test_stream.mp3\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    base64_data = base64.b64encode(data).decode(\"utf-8\")\n",
    "payload = {\n",
    "    \"audio_data\": base64_data,\n",
    "    \"file_extension\": \"wav\",\n",
    "    \"language\": \"en\"\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:62343/transcribe_base64/\", json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63cf90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 1.4804470539093018\n",
      "16000 1.4844787120819092\n",
      "16000 1.5025901794433594\n",
      "16000 1.505432367324829\n",
      "16000 1.5065157413482666\n",
      "16000 1.511488676071167\n",
      "16000 1.5252833366394043\n",
      "13904 1.5284266471862793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='test_stream.mp3'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import httpx\n",
    "from io import BytesIO\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "async def generate_speech_stream(prompt_audio_url, text):\n",
    "    # 1. regenerate speech\n",
    "    # 2. return speech url\n",
    "    try:\n",
    "        payload = {\n",
    "            \"prompt_audio_url\": prompt_audio_url,\n",
    "            \"text\": text,\n",
    "            # \"temperature\": 0.3,\n",
    "            # \"top_p\": 0.8,\n",
    "            # \"top_k\": 30,\n",
    "            # \"max_tokens\": 1850,\n",
    "            # \"repetition_penalty\": 10.0,\n",
    "            # \"seed\": 42,\n",
    "            # \"crossfade_ms\": 1,\n",
    "            # \"interval_silence\": 200\n",
    "        }\n",
    "        async with httpx.AsyncClient(follow_redirects=True) as client:\n",
    "            async with client.stream(\n",
    "                \"POST\",\n",
    "                'http://voice.trustbeez.com/generate-speech-stream/',\n",
    "                json=payload,\n",
    "                follow_redirects=True,\n",
    "            ) as response:\n",
    "                async for chunk in response.aiter_bytes(chunk_size=16000):\n",
    "                    yield chunk\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "prompt_audio_url = \"https://beezstorageblob.blob.core.windows.net/emailblob/cloned_voice_7a8d8a62-6284-446a-9952-2e1481ba27d6.wav\"\n",
    "text = \"\"\"Enhancing Chess Skills Through Reading.\"\"\"\n",
    "concat_segment = None\n",
    "full_audio_bytes = BytesIO()\n",
    "start_time = time.time()\n",
    "async for chunk in generate_speech_stream(prompt_audio_url, text):\n",
    "    print(len(chunk), time.time() - start_time)\n",
    "    full_audio_bytes.write(chunk)\n",
    "full_audio_bytes.seek(0)\n",
    "audio_segment = AudioSegment.from_raw(full_audio_bytes, sample_width=2, frame_rate=22050, channels=1)\n",
    "audio_segment.export(\"test_stream.mp3\", format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'success', 'data': {'voice_report_url': 'https://beezstorageblob.blob.core.windows.net/emailblob/voice_report_bcfbc919-afe7-4450-96be-b4f5d0e79b1a.mp3', 'duration': 39.41}}\n",
      "Time taken to generate speech: 102.07 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "payload = {\n",
    "    \"prompt_audio_url\": \"https://beezstorageblob.blob.core.windows.net/emailblob/cloned_voice_7a8d8a62-6284-446a-9952-2e1481ba27d6.wav\",\n",
    "    \"text\": \"\"\"```title\\n## Encouraging Consistent Chess Practice\\n```\\n```report\\nTom could benefit from more consistent practice to really solidify his understanding and skills in chess. This is a common area for growth, and with some focused effort, we'll see great progress.\\n\\nTo help Tom get more accustomed to chess, we recommend establishing a fun, regular practice routine at home. Tom could try playing one or two quick games daily, either with family or on a platform like ChessKid. Solving a few chess puzzles each week through an app or workbook is also an excellent way to sharpen his mind. Aiming for around 2-4 hours of practice a week will build a strong foundation and keep the game enjoyable and engaging for him.\\n```\"\"\",\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:62343/generate-speech\", json=payload)\n",
    "print(response.json())\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to generate speech: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/RichooAgent\")\n",
    "import importlib\n",
    "from core.utils import common_utils\n",
    "importlib.reload(common_utils)\n",
    "from core.utils.common_utils import convert_markdown_to_text\n",
    "\n",
    "text = \"\"\"```title\n",
    "## Enhancing Chess Skills Through Reading\n",
    "```\n",
    "```report\n",
    "It's great to see Tom enthusiastic about chess in his 'Fall In-Person Chess Lessons - Level 0.' To help him build an even stronger foundation and accelerate his learning, it would be very beneficial for him to incorporate more reading into his chess routine at home.\n",
    "\n",
    "Reading chess books offers a wonderful way for Tom to reinforce concepts, explore new strategies, and deepen his understanding of the game. A great next step for Tom could be to explore beginner-friendly books like 'Chess for Children' or the 'Learning Chess Steps Booklets,' starting with Step 1. Encouraging Tom to dedicate a little time each week to these books will solidify his learning and set him up for more advanced play.\n",
    "```\"\"\"\n",
    "\n",
    "print(convert_markdown_to_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a04ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "start_time = time.time()\n",
    "payload = {\n",
    "    \"prompt_audio_url\": \"https://beezstorageblob.blob.core.windows.net/emailblob/cloned_voice_female1.wav\",\n",
    "    \"text\": \"\"\"```title\\n## Encouraging Consistent Chess Practice\\n```\\n```report\\nTom could benefit from more consistent practice to really solidify his understanding and skills in chess. This is a common area for growth, and with some focused effort, we'll see great progress.\\n\\nTo help Tom get more accustomed to chess, we recommend establishing a fun, regular practice routine at home. Tom could try playing one or two quick games daily, either with family or on a platform like ChessKid. Solving a few chess puzzles each week through an app or workbook is also an excellent way to sharpen his mind. Aiming for around 2-4 hours of practice a week will build a strong foundation and keep the game enjoyable and engaging for him.\\n```\"\"\",\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:62343/generate-speech\", json=payload)\n",
    "print(response.json())\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to generate speech: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "\n",
    "def enhance_voice(audio_file_path, output_file_path, noise_reduction_strength=0.8):\n",
    "    \"\"\"\n",
    "    对音频文件进行降噪和音量标准化，以增强人声。\n",
    "\n",
    "    参数:\n",
    "    audio_file_path (str): 输入音频文件的路径。\n",
    "    output_file_path (str): 处理后要保存的音频文件路径。\n",
    "    noise_reduction_strength (float): 降噪强度，介于 0 和 1 之间。\n",
    "                                     值越低，降噪越温和，但可能保留更多人声细节。\n",
    "                                     建议从 0.7 到 0.9 之间尝试。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 加载音频文件\n",
    "        print(\"正在加载音频文件...\")\n",
    "        audio_data, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "        # 2. 降噪处理\n",
    "        print(\"正在进行降噪...\")\n",
    "        # 使用传入的参数来控制降噪强度\n",
    "        reduced_noise_audio = nr.reduce_noise(y=audio_data, sr=sample_rate, prop_decrease=noise_reduction_strength)\n",
    "        print(\"降噪完成。\")\n",
    "\n",
    "        # 3. 音频标准化 (提升音量)\n",
    "        print(\"正在进行音量标准化...\")\n",
    "        # 将 NumPy 浮点数组转换为 pydub 所需的格式（16位整数）\n",
    "        # librosa 加载的范围是 -1.0 到 1.0，我们需要将其映射到 -32768 到 32767\n",
    "        int_audio_data = np.int16(reduced_noise_audio * 32767)\n",
    "\n",
    "        # 创建一个 pydub 的 AudioSegment 对象\n",
    "        # sample_width=2 表示 16位音频，channels=1 表示单声道\n",
    "        # 如果你的音频是立体声，需要将 channels 设置为 2\n",
    "        audio_segment = AudioSegment(\n",
    "            int_audio_data.tobytes(),\n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=2,  # 16-bit\n",
    "            channels=1      # 假设为单声道\n",
    "        )\n",
    "\n",
    "        # 应用标准化效果\n",
    "        # headroom 参数可以防止削波，默认是 0.1 dB\n",
    "        normalized_segment = normalize(audio_segment)\n",
    "        print(\"音量标准化完成。\")\n",
    "\n",
    "\n",
    "        # 4. 导出处理后的音频\n",
    "        print(f\"正在导出文件到: {output_file_path}\")\n",
    "        normalized_segment.export(output_file_path, format=\"wav\")\n",
    "\n",
    "        print(\"处理成功！\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理音频文件时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- 使用示例 ---\n",
    "if __name__ == '__main__':\n",
    "    # 输入你的音频文件路径\n",
    "    input_audio_path = '/workspace/RichooAgent/third_party/index-tts/data/enhanced_voice_audio.wav'  # 请替换成你自己的音频文件路径\n",
    "    # 定义输出文件的路径\n",
    "    output_audio_path = '/workspace/RichooAgent/third_party/index-tts/data/enhanced_voice_audio.wav'\n",
    "\n",
    "    # 调用函数处理音频\n",
    "    # 你可以调整 noise_reduction_strength 这个值来找到最佳平衡点\n",
    "    # - 值较低 (如 0.7): 降噪更温和，人声音量和细节保留得更好。\n",
    "    # - 值较高 (如 0.9): 降噪更彻底，但可能会对人声造成更多影响。\n",
    "    success = enhance_voice(\n",
    "        audio_file_path=input_audio_path,\n",
    "        output_file_path=output_audio_path,\n",
    "        noise_reduction_strength=0.9\n",
    "    )\n",
    "\n",
    "    if success:\n",
    "        print(f\"\\n任务完成！增强后的音频已保存为 '{output_audio_path}'。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "from pydub.effects import normalize\n",
    "def reduce_noise_and_normalize_volume_from_bytes(\n",
    "    audio_bytes: bytes,\n",
    "    sample_rate: int = None,\n",
    "    noise_reduction_strength: float = 0.9\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    对内存中的音频字节进行降噪和音量标准化，返回处理后的 WAV 字节。\n",
    "\n",
    "    参数:\n",
    "    audio_bytes (bytes): 原始音频字节（如从 base64 解码后的数据）\n",
    "    sample_rate (int): 如果已知采样率，可传入；否则自动检测\n",
    "    noise_reduction_strength (float): 降噪强度，0~1\n",
    "\n",
    "    返回:\n",
    "    bytes: 处理后的 WAV 音频字节\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 从字节加载音频数据\n",
    "        print(\"Loading audio from bytes...\")\n",
    "        audio_data, detected_sample_rate = librosa.load(io.BytesIO(audio_bytes), sr=sample_rate)\n",
    "\n",
    "        sample_rate = sample_rate or detected_sample_rate\n",
    "\n",
    "        # 2. 降噪\n",
    "        print(\"Reducing noise...\")\n",
    "        reduced_noise_audio = nr.reduce_noise(\n",
    "            y=audio_data,\n",
    "            sr=sample_rate,\n",
    "            prop_decrease=noise_reduction_strength\n",
    "        )\n",
    "        print(\"Noise reduction completed.\")\n",
    "\n",
    "        # 3. 音量标准化\n",
    "        print(\"Normalizing volume...\")\n",
    "        # 转换为 16-bit PCM\n",
    "        int_audio_data = np.int16(reduced_noise_audio * 32767)\n",
    "\n",
    "        # 创建 AudioSegment\n",
    "        audio_segment = AudioSegment(\n",
    "            data=int_audio_data.tobytes(),\n",
    "            sample_width=2,  # 16-bit\n",
    "            frame_rate=sample_rate,\n",
    "            channels=1       # 单声道，如需立体声需调整\n",
    "        )\n",
    "\n",
    "        normalized_segment = normalize(audio_segment, headroom=0.1)\n",
    "        print(\"Volume normalization completed.\")\n",
    "\n",
    "        # 4. 导出为字节（WAV 格式）\n",
    "        buffer = io.BytesIO()\n",
    "        normalized_segment.export(buffer, format=\"wav\")\n",
    "        buffer.seek(0)\n",
    "        processed_bytes = buffer.getvalue()\n",
    "\n",
    "        print(\"Audio processing from bytes successful!\")\n",
    "        return processed_bytes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio from bytes: {e}\")\n",
    "        raise  # 建议抛出异常，让上层捕获处理\n",
    "\n",
    "with open(\"/workspace/RichooAgent/third_party/index-tts/data/test_real.wav\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    processed_bytes = reduce_noise_and_normalize_volume_from_bytes(data)\n",
    "    with open(\"/workspace/RichooAgent/third_party/index-tts/data/test_realaaa.wav\", \"wb\") as f:\n",
    "        f.write(processed_bytes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
